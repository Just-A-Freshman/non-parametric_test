# 卡方检验
## 1.三种应用场景
### 1.1. 拟合优度检验
- 目的：检验观测分布是否符合某个理论分布。
- 例子：判断一个骰子是不是作弊骰子。相当于判断骰子的点数分布是不是均匀分布。

### 1.2.独立性检验
- 目的：检验**单个总体**中两个分类**变量**之间是否存在关联。通常我们会把一个变量看成自变量，另外一个看成因变量。
- 例子：判断男性和女性之间是否有跑步习惯的差异。
- 实践：从单个总体中随机抽取$m$人，按变量类别划分即可。“行总计”和“列总计”都是最后计算确定的，并非事先确定。

### 1.3.同质性检验
- 目的：检验多个**总体**分布是否相同。
- 例子：调查北京、上海、广州三个城市的居民（三个总体），判断他们的饮料（可乐、果汁、茶）偏好分布是否相同。
- 实践：我们预先设定好要从不同总体中都各抽$m$个人。也就是说，我们需要固定了“行合计”。

## 2. 核心公式
### 2.1. 检验统计量
假设把观测数据分为$k$个组，$O_i$为观测频数，$E_i$为理论频数，$n$为样本数，则：
$$\chi^2 = \sum_{i=1}^k \dfrac{(O_i - E_i)^2}{E_i}$$

注意这是定义式，将其展开后得到**计算式**，注意$\sum\limits_{i=1}^k O_i = \sum\limits_{i=1}^k E_i = n$，于是：
$$\chi^2 = \sum_{i=1}^k \dfrac{O_i^2}{E_i} - 2\sum_{i=1}^k O_i + \sum_{i=1}^k E_i = \sum_{i=1}^k \dfrac{O_i^2}{E_i} - n$$

### 2.2. 相关测量系数
#### 2.2.1 $\varphi$系数
- 公式：$$\varphi = \sqrt{\frac{\chi^2}{n}}$$
- 值域：$\varphi \in [0, +\infty)$，上界完全取决于行和列
- 适用场景：$2 \times 2$列联表。因为此时$\varphi \in [0, 1]$，越大代表相关性越强。

#### 2.2.2 $c$系数(少用)
- 公式：$$c = \sqrt{\frac{\chi^2}{\chi^2 + n}}$$
- 值域：$c \in [0, 1)$，上界完全取决于行和列
- 适用场景：任意$R \times C$列联表。但由于其上界取决于行和列，如$3 \times 3$时上界为$0.8165$。不同维度的列联表间的$c$系数没有可比性。

#### 2.2.3 $V$系数(最常用)
- 公式：$$V = \sqrt{\frac{\chi^2}{n \times \min[(R - 1), (C - 1)]}}$$
- 值域：$V \in [0, 1]$
- 适用场景：任意$R \times C$列联表。

##### 注意事项
- $V$的大小并不总是**直观**反映关联强度（例如，V=0.3可能表示中等关联），有时需要参考经验法则；
- 像所有基于卡方的度量一样，$V$系数受样本量影响。大样本下，即使关联很弱，卡方值也可能显著(**微小的关联被捕捉了**)，导致$V$系数值较小但显著。因此，它应**结合卡方检验结果一起解释**。



## 3. $\chi^2$分布的期望值准则
### 3.1.准则
- 当只有两个单元时，每个单元的期望频数必须$\geq 5$
- 当单元数$> 2$时，$80\%$以上的单元期望频数必须$\geq 5$

### 3.2.实践
当单元的期望频数太小时，适当**合并一些类别**。当样本量很大时，因为检验结果异常**灵敏**，容易出现相关系数很小但显著的情况。此时，$p$值将失去实践指导价值，我们必须结合相关系数值作出解释。

## 4. 关于卡方检验的分母
卡方检验的统计量是基于多项分布的渐近理论，在多项分布中，类别之间存在负协方差（因为总和固定），而皮尔逊卡方统计量隐含地考虑了这一点。直接使用$Var(O_i)$会忽略这种结构。

## 5. R代码实现
我们可以直接使用R语言内置的```chisq.test(data)```来进行卡方检验。当然，作为教学，我们可以自己手搓一个卡方检验的代码，它非常简单：
```r
chisqTest = function(data_matrix){
  row_num = nrow(data_matrix)
  col_num = ncol(data_matrix)
  df = (row_num - 1) * (col_num - 1)
  row_sum = matrix(rep(apply(data_matrix, 1, sum), col_num), row_num)
  col_sum = t(matrix(rep(apply(data_matrix, 2, sum), row_num), col_num))

  expected_matrix = row_sum * col_sum / sum(data_matrix)
  x_chisq = sum((data_matrix - expected_matrix)^2 / expected_matrix)
  p.value = pchisq(x_chisq, df, lower.tail = FALSE)

  result <- list(
    statistic = setNames(x_chisq, "X-squared"),
    parameter = c(df = df),
    p.value = p.value,
    method = "Pearson's Chi-squared test",
    data.name = deparse(substitute(data)),
    dimensions = c(row = row_num, col = col_num)
  )
  class(result) <- "htest"
  return(result)
}



if (sys.nframe() == 0) {
  data = matrix(c(
    83, 91, 41,
    70, 86, 38,
    45, 15, 10), nrow = 3
  )
  chisqTest(data)
}
```