# 单因素方差分析
## 1.方差分解
想象一下，我们想知道$k$组样本所对应的总体均值是否是一样的。为了方便，我们假设这$k$组样本的总体方差是一样的(方差齐性假定)。这样，原假设成立的情况下，$k$组样本就可以视为是从**同一个总体**中抽样后随机分组得到的。

方差分析的核心思想在于方差的分解。记：
- $\bar{x}$是所有样本点的均值。
- $x_{ij}$是第$i$组的第$j$个样本点。
- $\bar{x_{i.}}$是第$i$组样本的均值。

那么，$x_{ij}$的总变异可以分解成：
$$
x_{ij} - \bar{x} = (x_{ij} - \bar{x_{i.}}) + (\bar{x_{i.}} - \bar{x})
$$

其中，右边第一项是“组内个体与组均值的差异”，第二项是“组均值与总均值的差异”。我们对它们分别取平方求和。为了方便，记$\sum_{i=1}^k \sum_{j=1}^{n_i}$为$\sum_{ij}$，我们可以得到：
$$\begin{aligned}
\sum_{ij} \left( x_{ij} - \bar{x} \right)^2 &= \sum_{ij} [(x_{ij} - \bar{x_{i.}}) + (\bar{x_{i.}} - \bar{x})]^2 \\
&= \sum_{ij} \left( x_{ij} - \bar{x_{i.}} \right)^2 + \sum_{ij} \left( \bar{x_{i.}} - \bar{x} \right)^2
\end{aligned}$$

注意交叉项为0。这就是我们熟知的$SST = SSE + SSA$，即$SST$**总变异**可以分解成$SSE$**组内变异**和$SSA$**组间变异**。

## 2. 统计量
由于自由度会影响离差平方和的大小，为了标准化统一量纲，确保可比性，我们将$SST$、$SSE$和$SSA$分别除以自由度，就得到了：
- $MST = SST / (n - 1)$ —— $\bar{x}$消耗1个$df$
- $MSE = SSE / (n - k)$ —— $\bar{x_{i.}}$消耗$k$个$df$
- $MSA = SSA / (k - 1)$ —— $\bar{x}$消耗1个$df$

可以证明在原假设成立的情况下：
$$E(MSE) = E(MSA) = E(MET) = \sigma^2$$也就是说，分解后的组内均分和组间均分，都是总方差的无偏估计。我们选取两个分解方差的比值作为统计量：
$$
F = \frac{MSA}{MSE}
$$

## 3. 三大假设
三大假设指的是：
- 正态性假设
- 方差齐性假设
- 独立性假设

正态性假设和独立性假设是保证统计量服从$F$分布的必要条件。具体来说，当$x_{ij}$服从正态分布且相互独立时：
- $SSA / \sigma^2 \sim \chi^2(k - 1)$
- $SSE / \sigma^2 \sim \chi^2(n - k)$

同方差假定则一方面保证了原假设下所有样本都可以视为是从**同一个分布**中抽取的。另一方面是可以让未知的$\sigma^2$可以被约掉：
$$\begin{aligned}
F &= \frac{\chi^2(k - 1) / (k - 1)}{\chi^2(n - k) / (n - k)} \\
&= \frac{SSA / \sigma^2 / (k - 1)}{SSE / \sigma^2 / (n - k)} \\
&= \frac{MSA}{MSE}
\end{aligned}$$

## 4. 拒绝域
在原假设下，$F \to 1$. 但是当组与组之间存在系统性差异时，$MSA > MSE$，此时$F$值就会显著地大于1，属于右侧检验。因此拒绝域为：
$$
F > F_{1 - \alpha}(k - 1, n - k)
$$

## 5. 多组比较
方差分析解决了多组样本对应的总体均值之间等与不等的问题。但是，当单因素方差分析得出显著结果，说明至少有两个组之间存在显著差异后，我们并不知道具体是哪几对组之间不同。这时候就需要进行**事后多重比较**。

### 5.1 多重比较谬误
如果我们在ANOVA显著后，直接用两样本t检验对每对组进行比较，会因为比较次数的增加导致犯错概率累积，具体来说：

- 比较3个组，需要做 $C_3^2 = 3$ 次检验
- 比较5个组，需要做 $C_5^2 = 10$ 次检验  
- 比较k个组，需要做 $\frac{k(k-1)}{2}$ 次检验

如果每次检验的显著性水平设为 \(\alpha = 0.05\)，那么：
- 做1次检验：犯第一类错误的概率 = 5%
- 做10次检验：至少犯一次第一类错误的概率 ≈ \(1 - (1-0.05)^{10} ≈ 40\%\)

因此，想要得到合理结论，并控制犯第一类错误的概率，最好不要直接使用两样本的$t$检验。

ps: 但实际教科书中，通常就是采用两样本$t$检验做事后多重比较，即$Fisher$的$LSD$方法。虽然该方法直接使用会有偏误，但稍加改进还是可以使用的(Bonferroni 校正)。

### 5.2 常用的多重比较方法
#### 1. Tukey'S HSD
- **原理**：使用两样本数据的极差作为统计量，并构造极差分布。
- **应用**：各组**样本量相等**的情况最好，但也可用于样本量不等的情况。
- **检验效力**：较低，但控制**族错误率**

#### 2. Bonferroni 校正
- **原理**：把单次的显著性水平直接降低到$\alpha / m$。其中$m$为比较次数。然后正常使用$t$检验。
- **应用**：计算简单，适用性广。
- **检验效力**：较低

#### 3. Scheffé 方法
- **原理**：构造$\hat{L} = \sum_{i=1}^k c_k \bar{x_{i.}}$，将所有均值的比较纳入$L$中(如比较avg$(\bar{x_1},\bar{x_2})$和$\bar{x_3}$，则$c_1 = c_2 = 0.5, c_3 = -1$)。并围绕$L$构造统计量。
- **应用**：主要用于复杂对比，而不局限于两两比较
- **检验效力**：极低，但控制族错误率
