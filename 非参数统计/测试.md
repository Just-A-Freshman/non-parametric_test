# Kruskal-Wallis检验
## 1. 概述
Kruskal-Wallis单因素方差分析(下称KW检验)用于检验以下问题：
$$
\begin{aligned}
&H_0: M_1 = M2 = ... = M_n \\
&H_1: M_1,M_2,...,M_n不全相等
\end{aligned}
$$

他将所有不同样本数据全部混合后编秩，然后完全仿照参数统计的方差分析思想构造统计量。

## 2 统计量
### 2.1 形式
记$N$为总样本量，$\tau_j$为第$j$个结的结长，$\overline{R_i}$为第$i$组样本的平均秩，$R_{i.}$为第$i$组的秩和。那么KW的检验统计量如下：
$$
H = \frac{SSA}{MST}
$$只需再结合以下计算结果：
$$\begin{aligned}
&SSA = \sum_{i=1}^k n_i \overline{R_i}^2 - \frac{N(N + 1)^2}{4} \\
&MST = \frac{N(N + 1)}{12} \\
\end{aligned}$$最终化简得到计算式：
$$
H = \frac{12}{N(N+1)} \sum_{i=1}^k \frac{R_{i.}^2}{n_i} - 3(N+1)
$$

需要补充，当样本数据有结时，需要对$H$进行修正：$H_c = H \cdot c$，修正系数:
$$
c = 1 / \left[1 - \frac{\sum_{j=1}^g (\tau_j^3 - \tau_j)}{N^3 - N}\right]
$$

### 2.2 原因
我们简要解释一下为什么$H$统计量是$SSA/MST$这种形式：
1. 为了能**反映组间差异**，构造的统计量应当包含$SSA$或$MSA$；

2. 方差是**无量纲**的。为了能让统计量能和拒绝域对比，我们必须将方差进行标准化，即除以一个基准单位。基准单位应该是稳定的，反映到统计学上就是不论原假设成立与否，其值都差不多。在参数统计中，组内方差$MSE$就具有这一性质；而在非参数统计中，$MST$仅受样本量$N$影响，是更好的"基准方差"。因此统计量应当形如$MSA/MST$或$SSA/MST$。

3. 良好的**大样本性质**。当$N$足够大时，统计量应该近似服从某个分布，以便我们大样本近似。参数统计中，统计量$\frac{MSA}{MSE}$能够在三大假设成立的情况下服从$F$分布。而非参数统计中：
$$
\frac{SSA}{MST} = \frac{\sum_{i=1}^k (\overline{R_i} - \overline{R})^2}{\sigma^2} = \sum_{i=1}^k \left(\frac{\overline{R_i} - \overline{R}}{\sigma}\right)^2
$$这个统计量不仅在形式上靠近$\chi^2$分布($k$个标准正态分布的平方和)，并且被证实在大样本下服从$\chi^2(k - 1)$。这也是我们选择$SSA$做分子的理由。


## 3. 拒绝域
从$H = \frac{SSA}{MST}$的形式可知，在固定$n$的情况下，$MST$是确定的。$SSA$越大，即组间差异越大，$H$越大。因此，拒绝域在右侧，即：
$$
H > H_{1 - \alpha}
$$

## 4. 分布
### 4.1 小样本
小样本使用精确分布。因为秩的总数是确定的，其精确分布可以直接枚举。不过在具体枚举前，我们需要简要看看暴力枚举所需的计算量。

从$H$统计量可以看出，我们实际上只关心每组的秩和，而组内秩的顺序对我们来说是无关紧要的。如果考虑秩的所有排序，则总的排序数有$N!$种；但因为组内无序，因此需要将这些组内有序的情况除掉，总共就有：
$$
\frac{N!}{\prod_{i=1}^k n_i !}
$$总情况数随$N$的增大急剧升高。为了演示，我们取$N = 4, n_1 = 1, n_2 = 1, n_3 = 2$做精确分布的演示。使用"/"分离不同组的秩：
| 样本 | H | P |
|-------- |-------|------|
| 1/2/34，2/1/34，1/4/23，4/1/23，3/4/12，4/3/12 | 2.7 | 6 / 12 |
| 1/3/24，3/1/24，2/4/13，4/2/13 | 1.8 | 4 / 12 |
| 2/3/14，3/2/14 | 0.3 | 2 / 12 |

在这种情况下，如果观测到$H = 2.7$，那么$p = P(H \geq 2.7) = \frac{6}{12} = 0.5$，在$\alpha = 0.05$的情况下，不能拒绝原假设。

### 4.2 大样本
当样本量足够大时：
$$H \stackrel{.}{\sim} \chi^2(k - 1)$$因此临界值$H_{1 - \alpha}$可以近似为$\chi^2_{1 - \alpha}(1 - k)$。下面使用大样本近似时的参考条件：

| 组数(k) | 每组最小样本量 | 总样本量(N) | 近似效果 |
|---------|----------------|-------------|----------|
| 3 | ≥5 | ≥15 | 较好 |
| 4-6 | ≥4 | ≥16 | 良好 |
| ≥7 | ≥3 | ≥21 | 很好 |


## 5. 多组比较
### 5.1 参数统计中的多重比较
回顾参数统计中方差分析的多重比较。因为：
$$
\overline{x_{i.}} - \overline{x_{j.}} \sim N(\mu_i - \mu_j, \left(\frac{1}{n_i} + \frac{1}{n_j}\right)\sigma^2)
$$所以：
$$
\frac{(\overline{x_{i.}} - \overline{x_{j.}}) - (\mu_i - \mu_j)}{\sqrt{\left(\frac{1}{n_i} + \frac{1}{n_j}\right)\sigma^2}} \sim N(0, 1)
$$注意，$\sigma^2$是未知的，我们需要对其进行估计
- 如果原假设成立，$MSE$和$MST$都是$\sigma^2$的无偏估计。
- 如果原假设不成立，组间存在系统性不同，$MSA$就会明显偏大并影响$MST$。此时$MST$将无法用于估计$\sigma^2$
- $MSE$始终不受此影响。因此我们选择使用$MSE$来估计$\sigma$。

因为$MSE$是估计量，因此当我们使用$MSE$估计$\sigma$时，统计量的分布从正态分布变成了$t$分布，即：
$$
\frac{(\overline{x_{i.}} - \overline{x_{j.}}) - (\mu_i - \mu_j)}{\sqrt{\left(\frac{1}{n_i} + \frac{1}{n_j}\right)MSE}} \sim t(f_e)
$$

### 5.2 非参数统计中的多重比较
非参数的多重比较完全类似。只不过，$\sigma$用$MST$替代。但是需要注意：
- $MST$是理论方差，不是由样本估计得到的。即$\sigma$的准确值就等于$MST$。
- 因为$MST$不是估计量，因此统计量依然服从正态分布

因此：
$$
\frac{(\overline{R_i} - \overline{R_{j}}) - (M_i - M_j)}{\sqrt{\left(\frac{1}{n_i} + \frac{1}{n_j}\right) MST}} \sim N(0, 1)
$$

有结时，需要对$MST$进行修正：
$$
MST' = MST - \frac{\sum_{j=1}^g (\tau_j^3 - \tau_j)}{12(N - 1)}
$$

### 5.3 $p$值调整策略
#### 1. Bonferroni
- 思想：将每个个别检验的显著性水平调整为$\alpha / m$, $m$为比较次数
- 优点：最简单直接，严格控制FWER(Family-Wise Error Rate，即至少犯一次$I$类错误的概率)，适用于任何情况。
- 缺点：过于保守，检验效能较低

#### 2. Holm
- 思想：随排序位置(i)递增显著性水平($\alpha' = \frac{\alpha}{m - i + 1}$)
- 优点：对 Bonferroni 的改进，同样控制 FWER，但比 Bonferroni 更 “宽松”（效能更高），计算简单，适用范围广。
- 缺点：仍属于保守型方法，在比较次数极多时效能仍较低。

#### 3. BH（Benjamini-Hochberg）
- 随排序位置(i)递增显著性水平($\alpha' = \frac{i}{m} \cdot \alpha$)
- 优点：控制FDR(false discovery rate)，比控制 FWER 的方法更 “宽松”，效能更高，适合探索性研究（需发现更多潜在差异）。
- 缺点：仅在检验**统计量独立或正相关时**能有效控制 FDR；对负相关数据可能失效。

## 6. R代码实现
![例子](../../所有图片/KW检验.jpg)
输入数据：
```
data = c(
  3.7, 3.7, 3.0, 3.9, 2.7,
  7.3, 5.2, 5.3, 5.7, 6.5,
  9.0, 4.9, 7.1, 8.7
)

groups = c(rep("生活方式1", 5), rep("生活方式2", 5), rep("生活方式3", 4))
```
### 6.1 单因素方差分析
```
kruskal.test(data ~ groups)
```

运行结果：
```
Kruskal-Wallis rank sum test

data:  data by groups
Kruskal-Wallis chi-squared = 9.4322, df = 2, p-value =
0.00895
```
因为p-value < 0.05，因此拒绝原假设，认为三种减肥方法之间存在显著性差异。

### 6.2 多重比较
```
# install.packages("DescTools")
DescTools::DunnTest(data, groups, method = "holm")
```


运行结果：
```
Dunn's test of multiple comparisons using rank sums : holm  

                    mean.rank.diff   pval    
生活方式2-生活方式1            6.2 0.0380 *  
生活方式3-生活方式1            8.0 0.0130 *  
生活方式3-生活方式2            1.8 0.5208    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```
可以看到，生活方式1-2，1-3之间均有显著性差异。
